{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "-2yomfJx4gmA",
        "JErcX-9s3hjL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **구글 마운트 및 데이터, 라이브러리 호출 코드**"
      ],
      "metadata": {
        "id": "-2yomfJx4gmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD9HC6i-zgM2",
        "outputId": "5519d025-2e4f-4199-9356-ed551d40a493"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/WalBouss/GEM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8NAKdnpBIFT",
        "outputId": "a2d63f78-01ac-4647-f937-8cd3ecf1a45e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/WalBouss/GEM\n",
            "  Cloning https://github.com/WalBouss/GEM to /tmp/pip-req-build-hht6uu1r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/WalBouss/GEM /tmp/pip-req-build-hht6uu1r\n",
            "  Resolved https://github.com/WalBouss/GEM to commit a7d55f213619e9e85506b59e559a42bf25bb1a6e\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.24.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2025.11.3)\n",
            "Collecting ftfy (from gem_torch==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.36.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (5.29.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (1.0.22)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.8.1)\n",
            "Collecting open_clip_torch<=2.23.0 (from gem_torch==1.0)\n",
            "  Downloading open_clip_torch-2.23.0-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.5.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->gem_torch==1.0) (0.2.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->gem_torch==1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->gem_torch==1.0) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->gem_torch==1.0) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (2025.11.12)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->gem_torch==1.0) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->gem_torch==1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->gem_torch==1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.0->gem_torch==1.0) (3.0.3)\n",
            "Downloading open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gem_torch\n",
            "  Building wheel for gem_torch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gem_torch: filename=gem_torch-1.0-py3-none-any.whl size=11626 sha256=2c02e86753c1cd24d0e90f1d245b11193eaec0efa4149ed78e987983b651ed9c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qk203aem/wheels/d0/a3/cc/01f7a5be958f6bad42122edfefcb1f6479a821076d7c66524d\n",
            "Successfully built gem_torch\n",
            "Installing collected packages: ftfy, open_clip_torch, gem_torch\n",
            "Successfully installed ftfy-6.3.1 gem_torch-1.0 open_clip_torch-2.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WalBouss/GEM.git\n",
        "%cd GEM\n",
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao2c6mXhBI9c",
        "outputId": "d6be4355-31fb-428b-9f3e-4526374e2f94"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GEM'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/25)\u001b[K\rremote: Counting objects:   8% (2/25)\u001b[K\rremote: Counting objects:  12% (3/25)\u001b[K\rremote: Counting objects:  16% (4/25)\u001b[K\rremote: Counting objects:  20% (5/25)\u001b[K\rremote: Counting objects:  24% (6/25)\u001b[K\rremote: Counting objects:  28% (7/25)\u001b[K\rremote: Counting objects:  32% (8/25)\u001b[K\rremote: Counting objects:  36% (9/25)\u001b[K\rremote: Counting objects:  40% (10/25)\u001b[K\rremote: Counting objects:  44% (11/25)\u001b[K\rremote: Counting objects:  48% (12/25)\u001b[K\rremote: Counting objects:  52% (13/25)\u001b[K\rremote: Counting objects:  56% (14/25)\u001b[K\rremote: Counting objects:  60% (15/25)\u001b[K\rremote: Counting objects:  64% (16/25)\u001b[K\rremote: Counting objects:  68% (17/25)\u001b[K\rremote: Counting objects:  72% (18/25)\u001b[K\rremote: Counting objects:  76% (19/25)\u001b[K\rremote: Counting objects:  80% (20/25)\u001b[K\rremote: Counting objects:  84% (21/25)\u001b[K\rremote: Counting objects:  88% (22/25)\u001b[K\rremote: Counting objects:  92% (23/25)\u001b[K\rremote: Counting objects:  96% (24/25)\u001b[K\rremote: Counting objects: 100% (25/25)\u001b[K\rremote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 25 (delta 4), reused 20 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (25/25), 40.71 MiB | 56.41 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "/content/GEM\n",
            "Obtaining file:///content/GEM\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.24.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2025.11.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (6.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.36.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (5.29.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (1.0.22)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (0.8.1)\n",
            "Requirement already satisfied: open_clip_torch<=2.23.0 in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2.23.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from gem_torch==1.0) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->gem_torch==1.0) (3.5.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->gem_torch==1.0) (0.2.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->gem_torch==1.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->gem_torch==1.0) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->gem_torch==1.0) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->gem_torch==1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->gem_torch==1.0) (2025.11.12)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->gem_torch==1.0) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->gem_torch==1.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->gem_torch==1.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.0->gem_torch==1.0) (3.0.3)\n",
            "Installing collected packages: gem_torch\n",
            "  Attempting uninstall: gem_torch\n",
            "    Found existing installation: gem_torch 1.0\n",
            "    Uninstalling gem_torch-1.0:\n",
            "      Successfully uninstalled gem_torch-1.0\n",
            "  Running setup.py develop for gem_torch\n",
            "Successfully installed gem_torch-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "5i41tPy_BLWm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15c8cee2-caeb-4def-ed3f-a5b910d91a4e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.24.0+cu126)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (6.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.36.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.2.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (5.29.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.0.22)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (0.8.1)\n",
            "Requirement already satisfied: open_clip_torch<=2.23.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->-r requirements.txt (line 4)) (0.2.14)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirements.txt (line 6)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 13)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 15)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 15)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 15)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 15)) (2025.11.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 13)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.9.0->-r requirements.txt (line 1)) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2MBsWyiBOJ0",
        "outputId": "d65dcd54-1a61-4f9a-d313-d56772e05c88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **데이터 불러오기**"
      ],
      "metadata": {
        "id": "JErcX-9s3hjL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8ecnSsGzapC",
        "outputId": "d34d2c4d-c76a-4a3e-fff8-1be8c56455ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "저장 완료: /content/ADE20K_object150.txt (150 classes)\n",
            "['wall', 'building', 'sky', 'floor', 'tree', 'ceiling', 'road', 'bed', 'windowpane', 'grass']\n"
          ]
        }
      ],
      "source": [
        "input_path = \"/content/drive/MyDrive/OPEN-VOCABULARY/ADEChallengeData2016/objectInfo150.txt\"\n",
        "output_path = \"/content/ADE20K_object150.txt\"\n",
        "\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "classes = []\n",
        "for line in lines:\n",
        "    if line.strip() and not line.startswith(\"Idx\"):\n",
        "        name = line.strip().split(\"\\t\")[-1]\n",
        "        name = name.split(\",\")[0].strip()\n",
        "        classes.append(name)\n",
        "\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(classes))\n",
        "\n",
        "print(f\"저장 완료: {output_path} ({len(classes)} classes)\")\n",
        "print(classes[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "src_dir = \"/content/drive/MyDrive/OPEN-VOCABULARY/ADEChallengeData2016\"\n",
        "zip_path = \"/content/ade20k.zip\"\n",
        "\n",
        "shutil.make_archive(\"/content/ade20k\", 'zip', src_dir)\n",
        "print(f\"압축 완료: {zip_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnVAsaxJxFfq",
        "outputId": "5ce74e31-b584-4459-b3e7-e3326071e0e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "압축 완료: /content/ade20k.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/ade20k.zip -d /content/ADEChallengeData2016\n"
      ],
      "metadata": {
        "id": "OfGaQiXQ0PVp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ADE+heatmap 재구현 코드**"
      ],
      "metadata": {
        "id": "jR4IVUE_mYqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "_torch_load = torch.load\n",
        "def torch_load_wrapper(*args, **kwargs):\n",
        "    kwargs[\"weights_only\"] = False\n",
        "    return _torch_load(*args, **kwargs)\n",
        "torch.load = torch_load_wrapper\n",
        "\n",
        "OPENAI_DATASET_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
        "OPENAI_DATASET_STD  = (0.26862954, 0.26130258, 0.27577711)"
      ],
      "metadata": {
        "id": "vMKaUo5GeCzx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# ADE20K Dataset\n",
        "# ------------------------------------------------\n",
        "class ADE20K(Dataset):\n",
        "    PALETTE_FULL = torch.tensor([\n",
        "        [  0,   0,   0], [120, 120, 120], [180, 120, 120], [  6, 230, 230], [ 80,  50,  50],\n",
        "        [  4, 200,   3], [120, 120,  80], [140, 140, 140], [204,   5, 255], [230, 230, 230],\n",
        "        [  4, 250,   7], [224,   5, 255], [235, 255,   7], [150,   5,  61], [120, 120,  70],\n",
        "        [  8, 255,  51], [255,   6,  82], [143, 255, 140], [204, 255,   4], [255,  51,   7],\n",
        "        [204,  70,   3], [  0, 102, 200], [ 61, 230, 250], [255,   6,  51], [ 11, 102, 255],\n",
        "        [255,   7,  71], [255,   9, 224], [  9,   7, 230], [220, 220, 220], [255,   9,  92],\n",
        "        [112,   9, 255], [  8, 255, 214], [  7, 255, 224], [255, 184,   6], [ 10, 255,  71],\n",
        "        [255,  41,  10], [  7, 255, 255], [224, 255,   8], [102,   8, 255], [255,  61,   6],\n",
        "        [255, 194,   7], [255, 122,   8], [  0, 255,  20], [255,   8,  41], [255,   5, 153],\n",
        "        [  6,  51, 255], [235,  12, 255], [160, 150,  20], [  0, 163, 255], [140, 140, 140],\n",
        "        [250,  10,  15], [ 20, 255,   0], [ 31, 255,   0], [255,  31,   0], [255, 224,   0],\n",
        "        [153, 255,   0], [  0,   0, 255], [255,  71,   0], [  0, 235, 255], [  0, 173, 255],\n",
        "        [ 31,   0, 255], [ 11, 200, 200], [255,  82,   0], [  0, 255, 245], [  0,  61, 255],\n",
        "        [  0, 255, 112], [  0, 255, 133], [255,   0,   0], [255, 163,   0], [255, 102,   0],\n",
        "        [194, 255,   0], [  0, 143, 255], [ 51, 255,   0], [  0,  82, 255], [  0, 255,  41],\n",
        "        [  0, 255, 173], [ 10,   0, 255], [173, 255,   0], [  0, 255, 153], [255,  92,   0],\n",
        "        [255,   0, 255], [255,   0, 245], [255,   0, 102], [255, 173,   0], [255,   0,  20],\n",
        "        [255, 184, 184], [  0,  31, 255], [  0, 255,  61], [  0,  71, 255], [255,   0, 204],\n",
        "        [  0, 255, 194], [  0, 255,  82], [  0,  10, 255], [  0, 112, 255], [ 51,   0, 255],\n",
        "        [  0, 194, 255], [  0, 122, 255], [  0, 255, 163], [255, 153,   0], [  0, 255,  10],\n",
        "        [255, 112,   0], [143, 255,   0], [ 82,   0, 255], [163, 255,   0], [255, 235,   0],\n",
        "        [  8, 184, 170], [133,   0, 255], [  0, 255,  92], [184,   0, 255], [255,   0,  31],\n",
        "        [  0, 184, 255], [  0, 214, 255], [255,   0, 112], [ 92, 255,   0], [  0, 224, 255],\n",
        "        [112, 224, 255], [ 70, 184, 160], [163,   0, 255], [153,   0, 255], [ 71, 255,   0],\n",
        "        [255,   0, 163], [255, 204,   0], [255,   0, 143], [  0, 255, 235], [133, 255,   0],\n",
        "        [255,   0, 235], [245,   0, 255], [255,   0, 122], [255, 245,   0], [ 10, 190, 212],\n",
        "        [214, 255,   0], [  0, 204, 255], [ 20,   0, 255], [255, 255,   0], [  0, 153, 255],\n",
        "        [  0,  41, 255], [  0, 255, 204], [ 41,   0, 255], [ 41, 255,   0], [173,   0, 255],\n",
        "        [  0, 245, 255], [ 71,   0, 255], [122,   0, 255], [  0, 255, 184], [  0,  92, 255],\n",
        "        [184, 255,   0], [  0, 133, 255], [255, 214,   0], [ 25, 194, 194], [102, 255,   0],\n",
        "        [ 92,   0, 255]\n",
        "    ], dtype=torch.uint8)\n",
        "\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 split='validation',\n",
        "                 transform=None,\n",
        "                 ignore_index=-1,\n",
        "                 resize_mask=False,\n",
        "                 classes_txt='/content/ADE20K_object150.txt'):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.split = split\n",
        "        self.ignore_index = ignore_index\n",
        "        self.transform = transform if transform is not None else SegmentationTransforms(\n",
        "            (448, 448), resize_mask=resize_mask\n",
        "        )\n",
        "        self.image_dir = os.path.join(root, 'images', split)\n",
        "        self.label_dir = os.path.join(root, 'annotations', split)\n",
        "\n",
        "        with open(classes_txt, 'r', encoding='utf-8') as f:\n",
        "            self.CLASSES = [line.strip() for line in f]\n",
        "        assert len(self.CLASSES) == 150, f\"Expected 150 classes, got {len(self.CLASSES)}\"\n",
        "\n",
        "        pal_full = self.PALETTE_FULL.numpy().astype(np.uint32)\n",
        "        pal = pal_full[1:] if pal_full.shape[0] == 151 else pal_full\n",
        "        assert pal.shape[0] == 150, f\"Palette must be 150 colors, got {pal.shape[0]}\"\n",
        "\n",
        "        self._pal_150 = pal\n",
        "        packed_pal = (pal[:, 0] << 16) | (pal[:, 1] << 8) | pal[:, 2]\n",
        "        self._pack_palette = {int(p): i for i, p in enumerate(packed_pal)}\n",
        "\n",
        "        self.image_files = sorted([\n",
        "            os.path.join(self.image_dir, f)\n",
        "            for f in os.listdir(self.image_dir)\n",
        "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ])\n",
        "        self.label_files = sorted([\n",
        "            os.path.join(self.label_dir, f)\n",
        "            for f in os.listdir(self.label_dir)\n",
        "            if f.lower().endswith('.png')\n",
        "        ])\n",
        "        assert len(self.image_files) == len(self.label_files), \"Image/Label count mismatch\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def _rgb_mask_to_index(self, rgb_target: torch.Tensor) -> torch.Tensor:\n",
        "        rgb = rgb_target.permute(1, 2, 0).contiguous().numpy().astype(np.uint32)\n",
        "        packed = (rgb[..., 0] << 16) | (rgb[..., 1] << 8) | rgb[..., 2]\n",
        "        flat = packed.reshape(-1)\n",
        "        mapped = np.full(flat.shape, self.ignore_index, dtype=np.int64)\n",
        "        for k, v in self._pack_palette.items():\n",
        "            mapped[flat == k] = v\n",
        "        idx_mask = mapped.reshape(packed.shape)\n",
        "        return torch.from_numpy(idx_mask).long()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = self.image_files[idx]\n",
        "        label_path = self.label_files[idx]\n",
        "\n",
        "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "        lab_im = Image.open(label_path)\n",
        "        lab_np = np.array(lab_im)\n",
        "\n",
        "        if lab_np.ndim == 2:\n",
        "            idx_mask = lab_np.astype(np.int64)\n",
        "            bg = (idx_mask == 0)\n",
        "            idx_mask = idx_mask - 1\n",
        "            idx_mask[bg] = self.ignore_index\n",
        "            index_mask = torch.from_numpy(idx_mask).long()\n",
        "            images, _ = self.transform(img_pil, img_pil)\n",
        "        else:\n",
        "            images, rgb_target = self.transform(img_pil, lab_im.convert(\"RGB\"))\n",
        "            index_mask = self._rgb_mask_to_index(rgb_target)\n",
        "\n",
        "        return images, index_mask\n",
        "\n",
        "\n",
        "class ToTensorMask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ToTensorMask, self).__init__()\n",
        "\n",
        "    def forward(self, mask):\n",
        "        return torch.as_tensor(np.array(mask), dtype=torch.uint8).permute(2, 0, 1)\n",
        "\n",
        "\n",
        "class SegmentationTransforms(object):\n",
        "    def __init__(self, size, img_transforms=None, resize_mask=False):\n",
        "        self.img_transforms = img_transforms if img_transforms is not None else transforms.Compose([\n",
        "            transforms.Resize(size=size, interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(OPENAI_DATASET_MEAN, OPENAI_DATASET_STD),\n",
        "        ])\n",
        "        self.mask_transforms = transforms.Compose([\n",
        "            transforms.Resize(size=size) if resize_mask else nn.Identity(),\n",
        "            ToTensorMask(),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, image, mask):\n",
        "        return self.img_transforms(image), self.mask_transforms(mask)"
      ],
      "metadata": {
        "id": "Cu0DR6QzeC8a"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# Zero-Shot Evaluator\n",
        "# ------------------------------------------------\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.classification import MulticlassJaccardIndex\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import gem\n",
        "\n",
        "class ZeroShotSegmentation(torch.nn.Module):\n",
        "    def __init__(self, model, tokenizer, model_name, patch_size=16, device='cpu',\n",
        "                 class_chunk=32):\n",
        "        super(ZeroShotSegmentation, self).__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.device = device\n",
        "\n",
        "        self.gem_model = model\n",
        "        self.gem_model.to(device)\n",
        "        self.gem_model.eval()\n",
        "        self.patch_size = patch_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.class_chunk = class_chunk\n",
        "\n",
        "    def _get_text_embedding(self, classes: list):\n",
        "        prompts = [f'a photo of a {cls}.' for cls in classes]\n",
        "\n",
        "        tokenized_prompts = self.tokenizer(prompts).to(self.device)\n",
        "\n",
        "        text_embedding = self.gem_model.model.encode_text(tokenized_prompts)\n",
        "        text_embedding = F.normalize(text_embedding, dim=-1)\n",
        "        return text_embedding.unsqueeze(0)\n",
        "\n",
        "    def _visual_features(self, image):\n",
        "        with torch.inference_mode(), torch.cuda.amp.autocast(enabled=image.is_cuda):\n",
        "            feat, _ = self.gem_model.model.visual(image)\n",
        "            feat = F.normalize(feat, dim=-1)[:, 1:]\n",
        "        return feat\n",
        "\n",
        "    def inference_chunked(self, image, text_embedding, mask_shape_hw):\n",
        "        B, _, H, W = image.shape\n",
        "\n",
        "        feat = self._visual_features(image)\n",
        "        C = text_embedding.shape[1]\n",
        "\n",
        "        chunks = []\n",
        "        for s in range(0, C, self.class_chunk):\n",
        "            te = text_embedding[:, s:s+self.class_chunk]\n",
        "            lg = 100.0 * torch.matmul(feat, te.transpose(1, 2))\n",
        "            chunks.append(lg)\n",
        "            del te, lg\n",
        "            if image.is_cuda:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        logits_flat = torch.cat(chunks, dim=-1)\n",
        "\n",
        "        h, w = H // self.patch_size, W // self.patch_size\n",
        "        logits = logits_flat.view(B, h, w, C)\n",
        "        logits = logits.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "        logits = F.interpolate(logits, size=mask_shape_hw, mode='bilinear', align_corners=False)\n",
        "        pred = logits.argmax(1)\n",
        "        return pred, logits, feat\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_dataset(self, dataloader, classes, device):\n",
        "        C = len(classes)\n",
        "        text_embedding = self._get_text_embedding(classes)\n",
        "\n",
        "        confmat = np.zeros((C, C), dtype=np.int64)\n",
        "\n",
        "        img_counter = 0\n",
        "\n",
        "        for images, masks in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            pred_gem, logits_chunk, feat = self.inference_chunked(images, text_embedding, masks.shape[-2:])\n",
        "\n",
        "            B = images.shape[0]\n",
        "            for b in range(B):\n",
        "                img_path = dataloader.dataset.image_files[img_counter]\n",
        "                img_original = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "                base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "                img_counter += 1\n",
        "\n",
        "                save_predicted_heatmaps(\n",
        "                    img_original,\n",
        "                    logits_chunk[b].unsqueeze(0),\n",
        "                    pred_gem[b].unsqueeze(0),\n",
        "                    classes,\n",
        "                    \"./ade_heatmaps\",\n",
        "                    base_name,\n",
        "                )\n",
        "\n",
        "                gt = masks[b].reshape(-1).cpu()\n",
        "                pr = pred_gem[b].reshape(-1).cpu()\n",
        "\n",
        "                valid = gt >= 0\n",
        "                gt = gt[valid]\n",
        "                pr = pr[valid]\n",
        "\n",
        "                idx = gt * C + pr\n",
        "                cm_flat = torch.bincount(idx, minlength=C*C)\n",
        "                cm = cm_flat.view(C, C).numpy()\n",
        "                confmat += cm\n",
        "\n",
        "        tp = np.diag(confmat).astype(np.float64)\n",
        "        fp = confmat.sum(axis=0) - tp\n",
        "        fn = confmat.sum(axis=1) - tp\n",
        "        denom = tp + fp + fn\n",
        "        iou = np.where(denom > 0, tp / denom, np.nan)\n",
        "        miou = float(np.nanmean(iou) * 100.0)\n",
        "\n",
        "        print('\\n======================================')\n",
        "        print(f'✅ 최종 mIoU: {miou:.2f}  (ADE20K 150-class)')\n",
        "        print('======================================')\n",
        "\n",
        "        return miou\n"
      ],
      "metadata": {
        "id": "U4RUKqGjeDAK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predicted_heatmaps(original_img, logits, pred_mask, classes, save_dir, base_name):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    img = original_img.astype(np.float32) / 255.0\n",
        "    H0, W0, _ = img.shape\n",
        "\n",
        "    pred_classes = torch.unique(pred_mask).cpu().tolist()\n",
        "\n",
        "    for cls_idx in pred_classes:\n",
        "        if cls_idx < 0:\n",
        "            continue\n",
        "\n",
        "        heatmap = logits[0, cls_idx].detach().cpu().numpy()\n",
        "\n",
        "        heatmap = cv2.resize(heatmap, (W0, H0))\n",
        "\n",
        "        if heatmap.max() == heatmap.min():\n",
        "            norm = heatmap\n",
        "        else:\n",
        "            norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Original\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(img, alpha=0.5)\n",
        "        plt.imshow(norm, cmap=\"jet\", alpha=0.5)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"{classes[cls_idx]}\")\n",
        "\n",
        "        filename = f\"{base_name}_{classes[cls_idx]}.png\"\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, filename))\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "Y_W13y-fpN9i"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# Main\n",
        "# ------------------------------------------------\n",
        "def main(model_name, device, pretrained,patch_size=16, root_path_ade='', batch_size=1, classes_txt='/content/ADE20K_object150.txt'):\n",
        "    dataset = ADE20K(root=root_path_ade, split='validation',\n",
        "                    transform=SegmentationTransforms((448, 448), resize_mask=(batch_size > 1)),\n",
        "                    ignore_index=-1,classes_txt=classes_txt)\n",
        "    classes_list = list(dataset.CLASSES)\n",
        "    if os.name == 'nt':\n",
        "        num_workers = 0\n",
        "        persistent_workers = False\n",
        "    else:\n",
        "        num_workers = max(2, (os.cpu_count() or 4) // 2)\n",
        "        persistent_workers = True\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
        "        pin_memory=(device.type == \"cuda\"),\n",
        "        persistent_workers=persistent_workers\n",
        "    )\n",
        "\n",
        "    model = gem.create_gem_model(model_name=model_name, pretrained=pretrained)\n",
        "    tokenizer = gem.get_tokenizer(model_name=model_name)\n",
        "\n",
        "    evaluator = ZeroShotSegmentation(model=model,device=device, patch_size=patch_size,\n",
        "                                     model_name=model_name,tokenizer=tokenizer,class_chunk=32)\n",
        "\n",
        "    miou = evaluator.eval_dataset(\n",
        "        dataloader=test_loader,\n",
        "        classes=classes_list,\n",
        "        device=device\n",
        "    )\n",
        "    return miou\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    patch_size    = 16\n",
        "    model_name    = 'ViT-B-16'\n",
        "    pretrained    = 'openai'\n",
        "    root_path_ade = '/content/ADEChallengeData2016'\n",
        "    classes_txt   = '/content/ADE20K_object150.txt'\n",
        "\n",
        "    print('########################################')\n",
        "    print(f'model: {model_name} | pretrained: {pretrained}')\n",
        "    print('########################################')\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    final_miou = main(\n",
        "        model_name=model_name,\n",
        "        pretrained=pretrained,\n",
        "        device=device,\n",
        "        patch_size=patch_size,\n",
        "        root_path_ade=root_path_ade,\n",
        "        classes_txt=classes_txt,\n",
        "        batch_size=1\n",
        "    )\n",
        "    print(f\"Final mIoU: {final_miou:.2f}\")"
      ],
      "metadata": {
        "id": "fo5iqYrU2MFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ADE + CTG_heatmap 코드**"
      ],
      "metadata": {
        "id": "hJRR6u1F4vSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "_torch_load = torch.load\n",
        "def torch_load_wrapper(*args, **kwargs):\n",
        "    kwargs[\"weights_only\"] = False\n",
        "    return _torch_load(*args, **kwargs)\n",
        "torch.load = torch_load_wrapper\n",
        "\n",
        "OPENAI_DATASET_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
        "OPENAI_DATASET_STD  = (0.26862954, 0.26130258, 0.27577711)"
      ],
      "metadata": {
        "id": "2iGRfrZ44vSs"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# ADE20K Dataset\n",
        "# ------------------------------------------------\n",
        "class ADE20K(Dataset):\n",
        "    PALETTE_FULL = torch.tensor([\n",
        "        [  0,   0,   0], [120, 120, 120], [180, 120, 120], [  6, 230, 230], [ 80,  50,  50],\n",
        "        [  4, 200,   3], [120, 120,  80], [140, 140, 140], [204,   5, 255], [230, 230, 230],\n",
        "        [  4, 250,   7], [224,   5, 255], [235, 255,   7], [150,   5,  61], [120, 120,  70],\n",
        "        [  8, 255,  51], [255,   6,  82], [143, 255, 140], [204, 255,   4], [255,  51,   7],\n",
        "        [204,  70,   3], [  0, 102, 200], [ 61, 230, 250], [255,   6,  51], [ 11, 102, 255],\n",
        "        [255,   7,  71], [255,   9, 224], [  9,   7, 230], [220, 220, 220], [255,   9,  92],\n",
        "        [112,   9, 255], [  8, 255, 214], [  7, 255, 224], [255, 184,   6], [ 10, 255,  71],\n",
        "        [255,  41,  10], [  7, 255, 255], [224, 255,   8], [102,   8, 255], [255,  61,   6],\n",
        "        [255, 194,   7], [255, 122,   8], [  0, 255,  20], [255,   8,  41], [255,   5, 153],\n",
        "        [  6,  51, 255], [235,  12, 255], [160, 150,  20], [  0, 163, 255], [140, 140, 140],\n",
        "        [250,  10,  15], [ 20, 255,   0], [ 31, 255,   0], [255,  31,   0], [255, 224,   0],\n",
        "        [153, 255,   0], [  0,   0, 255], [255,  71,   0], [  0, 235, 255], [  0, 173, 255],\n",
        "        [ 31,   0, 255], [ 11, 200, 200], [255,  82,   0], [  0, 255, 245], [  0,  61, 255],\n",
        "        [  0, 255, 112], [  0, 255, 133], [255,   0,   0], [255, 163,   0], [255, 102,   0],\n",
        "        [194, 255,   0], [  0, 143, 255], [ 51, 255,   0], [  0,  82, 255], [  0, 255,  41],\n",
        "        [  0, 255, 173], [ 10,   0, 255], [173, 255,   0], [  0, 255, 153], [255,  92,   0],\n",
        "        [255,   0, 255], [255,   0, 245], [255,   0, 102], [255, 173,   0], [255,   0,  20],\n",
        "        [255, 184, 184], [  0,  31, 255], [  0, 255,  61], [  0,  71, 255], [255,   0, 204],\n",
        "        [  0, 255, 194], [  0, 255,  82], [  0,  10, 255], [  0, 112, 255], [ 51,   0, 255],\n",
        "        [  0, 194, 255], [  0, 122, 255], [  0, 255, 163], [255, 153,   0], [  0, 255,  10],\n",
        "        [255, 112,   0], [143, 255,   0], [ 82,   0, 255], [163, 255,   0], [255, 235,   0],\n",
        "        [  8, 184, 170], [133,   0, 255], [  0, 255,  92], [184,   0, 255], [255,   0,  31],\n",
        "        [  0, 184, 255], [  0, 214, 255], [255,   0, 112], [ 92, 255,   0], [  0, 224, 255],\n",
        "        [112, 224, 255], [ 70, 184, 160], [163,   0, 255], [153,   0, 255], [ 71, 255,   0],\n",
        "        [255,   0, 163], [255, 204,   0], [255,   0, 143], [  0, 255, 235], [133, 255,   0],\n",
        "        [255,   0, 235], [245,   0, 255], [255,   0, 122], [255, 245,   0], [ 10, 190, 212],\n",
        "        [214, 255,   0], [  0, 204, 255], [ 20,   0, 255], [255, 255,   0], [  0, 153, 255],\n",
        "        [  0,  41, 255], [  0, 255, 204], [ 41,   0, 255], [ 41, 255,   0], [173,   0, 255],\n",
        "        [  0, 245, 255], [ 71,   0, 255], [122,   0, 255], [  0, 255, 184], [  0,  92, 255],\n",
        "        [184, 255,   0], [  0, 133, 255], [255, 214,   0], [ 25, 194, 194], [102, 255,   0],\n",
        "        [ 92,   0, 255]\n",
        "    ], dtype=torch.uint8)\n",
        "\n",
        "    def __init__(self,\n",
        "                 root,\n",
        "                 split='validation',\n",
        "                 transform=None,\n",
        "                 ignore_index=-1,\n",
        "                 resize_mask=False,\n",
        "                 classes_txt='/content/ADE20K_object150.txt'):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.split = split\n",
        "        self.ignore_index = ignore_index\n",
        "        self.transform = transform if transform is not None else SegmentationTransforms(\n",
        "            (448, 448), resize_mask=resize_mask\n",
        "        )\n",
        "        self.image_dir = os.path.join(root, 'images', split)\n",
        "        self.label_dir = os.path.join(root, 'annotations', split)\n",
        "\n",
        "        with open(classes_txt, 'r', encoding='utf-8') as f:\n",
        "            self.CLASSES = [line.strip() for line in f]\n",
        "        assert len(self.CLASSES) == 150, f\"Expected 150 classes, got {len(self.CLASSES)}\"\n",
        "\n",
        "        pal_full = self.PALETTE_FULL.numpy().astype(np.uint32)\n",
        "        pal = pal_full[1:] if pal_full.shape[0] == 151 else pal_full\n",
        "        assert pal.shape[0] == 150, f\"Palette must be 150 colors, got {pal.shape[0]}\"\n",
        "\n",
        "        self._pal_150 = pal\n",
        "        packed_pal = (pal[:, 0] << 16) | (pal[:, 1] << 8) | pal[:, 2]\n",
        "        self._pack_palette = {int(p): i for i, p in enumerate(packed_pal)}\n",
        "\n",
        "        self.image_files = sorted([\n",
        "            os.path.join(self.image_dir, f)\n",
        "            for f in os.listdir(self.image_dir)\n",
        "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ])\n",
        "        self.label_files = sorted([\n",
        "            os.path.join(self.label_dir, f)\n",
        "            for f in os.listdir(self.label_dir)\n",
        "            if f.lower().endswith('.png')\n",
        "        ])\n",
        "        assert len(self.image_files) == len(self.label_files), \"Image/Label count mismatch\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def _rgb_mask_to_index(self, rgb_target: torch.Tensor) -> torch.Tensor:\n",
        "        rgb = rgb_target.permute(1, 2, 0).contiguous().numpy().astype(np.uint32)\n",
        "        packed = (rgb[..., 0] << 16) | (rgb[..., 1] << 8) | rgb[..., 2]\n",
        "        flat = packed.reshape(-1)\n",
        "        mapped = np.full(flat.shape, self.ignore_index, dtype=np.int64)\n",
        "        for k, v in self._pack_palette.items():\n",
        "            mapped[flat == k] = v\n",
        "        idx_mask = mapped.reshape(packed.shape)\n",
        "        return torch.from_numpy(idx_mask).long()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_path = self.image_files[idx]\n",
        "        label_path = self.label_files[idx]\n",
        "\n",
        "        img_pil = Image.open(img_path).convert(\"RGB\")\n",
        "        lab_im = Image.open(label_path)\n",
        "        lab_np = np.array(lab_im)\n",
        "\n",
        "        if lab_np.ndim == 2:\n",
        "            idx_mask = lab_np.astype(np.int64)\n",
        "            bg = (idx_mask == 0)\n",
        "            idx_mask = idx_mask - 1\n",
        "            idx_mask[bg] = self.ignore_index\n",
        "            index_mask = torch.from_numpy(idx_mask).long()\n",
        "            images, _ = self.transform(img_pil, img_pil)\n",
        "        else:\n",
        "            images, rgb_target = self.transform(img_pil, lab_im.convert(\"RGB\"))\n",
        "            index_mask = self._rgb_mask_to_index(rgb_target)\n",
        "\n",
        "        return images, index_mask\n",
        "\n",
        "\n",
        "class ToTensorMask(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ToTensorMask, self).__init__()\n",
        "\n",
        "    def forward(self, mask):\n",
        "        return torch.as_tensor(np.array(mask), dtype=torch.uint8).permute(2, 0, 1)\n",
        "\n",
        "\n",
        "class SegmentationTransforms(object):\n",
        "    def __init__(self, size, img_transforms=None, resize_mask=False):\n",
        "        self.img_transforms = img_transforms if img_transforms is not None else transforms.Compose([\n",
        "            transforms.Resize(size=size, interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(OPENAI_DATASET_MEAN, OPENAI_DATASET_STD),\n",
        "        ])\n",
        "        self.mask_transforms = transforms.Compose([\n",
        "            transforms.Resize(size=size) if resize_mask else nn.Identity(),\n",
        "            ToTensorMask(),\n",
        "        ])\n",
        "\n",
        "    def __call__(self, image, mask):\n",
        "        return self.img_transforms(image), self.mask_transforms(mask)"
      ],
      "metadata": {
        "id": "UiWW0kwq4vSs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# CTG\n",
        "# ------------------------------------------------\n",
        "class CTG(nn.Module):\n",
        "    def __init__(self,\n",
        "                 pos_ratio: float = 0.1,   # 상위 k% (양성 시드)\n",
        "                 neg_ratio: float = 0.1,   # 하위 k% (음성 시드)\n",
        "                 alpha: float = 0.5,       # 원로짓 vs CTG 로짓 가중치\n",
        "                 tau: float = 9.0,        # 스코어 스케일 (temperature)\n",
        "                 iters: int = 1):          # 반복 횟수\n",
        "        super().__init__()\n",
        "        self.pos_ratio = pos_ratio\n",
        "        self.neg_ratio = neg_ratio\n",
        "        self.alpha = alpha\n",
        "        self.tau = tau\n",
        "        self.iters = max(1, iters)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward(self, feat_hwxd, logits_hwxc):\n",
        "        \"\"\"\n",
        "        feat_hwxd : [B, H, W, D] (patch feature)\n",
        "        logits_hwxc : [B, H, W, C] (클래스별 patch score)\n",
        "        \"\"\"\n",
        "        B, H, W, D = feat_hwxd.shape\n",
        "        _, _, _, C = logits_hwxc.shape\n",
        "        cur = logits_hwxc\n",
        "\n",
        "        for _ in range(self.iters):\n",
        "            scores = cur.permute(0, 3, 1, 2).reshape(B, C, H * W)\n",
        "\n",
        "            k_pos = max(1, int(self.pos_ratio * H * W))\n",
        "            k_neg = max(1, int(self.neg_ratio * H * W))\n",
        "\n",
        "            feat = F.normalize(feat_hwxd.reshape(B, H * W, D), dim=-1)\n",
        "\n",
        "            pos_proto = torch.zeros(B, C, D, device=feat.device)\n",
        "            neg_proto = torch.zeros(B, C, D, device=feat.device)\n",
        "\n",
        "            top_vals, top_idx = torch.topk(scores, k=k_pos, dim=-1, largest=True, sorted=False)\n",
        "            bot_vals, bot_idx = torch.topk(scores, k=k_neg, dim=-1, largest=False, sorted=False)\n",
        "\n",
        "            for b in range(B):\n",
        "                for c in range(C):\n",
        "                    pos_feats = feat[b, top_idx[b, c]]\n",
        "                    neg_feats = feat[b, bot_idx[b, c]]\n",
        "                    pos_proto[b, c] = F.normalize(pos_feats.mean(dim=0, keepdim=True), dim=-1)\n",
        "                    neg_proto[b, c] = F.normalize(neg_feats.mean(dim=0, keepdim=True), dim=-1)\n",
        "\n",
        "            sim_pos = torch.einsum('bnd,bcd->bnc', feat, pos_proto)\n",
        "            sim_neg = torch.einsum('bnd,bcd->bnc', feat, neg_proto)\n",
        "            ctg_score = self.tau * (sim_pos - sim_neg)\n",
        "\n",
        "            ctg_score = ctg_score.reshape(B, H, W, C)\n",
        "            cur = (1.0 - self.alpha) * cur + self.alpha * ctg_score\n",
        "\n",
        "        return cur\n",
        "\n",
        "\n",
        "class CTGWrapper(nn.Module):\n",
        "    def __init__(self, patch_size=16, ctg_cfg=None):\n",
        "        super().__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.ctg = CTG(**(ctg_cfg or {}))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def refine(self, feat_tokens_bnd, H, W, logits_bchw, mask_shape):\n",
        "        \"\"\"\n",
        "        feat_tokens_bnd : [B, N, D] (CLS 제거된 patch 토큰)\n",
        "        logits_bchw     : [B, C, h, w] (CLIP patch grid 로짓)\n",
        "        mask_shape      : (H_out, W_out)\n",
        "        \"\"\"\n",
        "        B, C, h, w = logits_bchw.shape\n",
        "        feat_hwxd = feat_tokens_bnd.reshape(B, h, w, -1)\n",
        "\n",
        "        logits_hwxc = logits_bchw.permute(0, 2, 3, 1).contiguous()\n",
        "        refined_hwxc = self.ctg(feat_hwxd, logits_hwxc)\n",
        "\n",
        "        refined_bchw = refined_hwxc.permute(0, 3, 1, 2).contiguous()\n",
        "        refined_bchw = F.interpolate(refined_bchw, size=mask_shape, mode='bilinear', align_corners=False)\n",
        "        return refined_bchw\n"
      ],
      "metadata": {
        "id": "qfS2oRPJsfaQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# Zero-Shot Evaluator\n",
        "# ------------------------------------------------\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.classification import MulticlassJaccardIndex\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "import gem\n",
        "\n",
        "class ZeroShotSegmentation(torch.nn.Module):\n",
        "    def __init__(self, model, tokenizer, model_name, patch_size=16, device='cpu', class_chunk=32,\n",
        "                 use_ctg: bool = True,\n",
        "                 ctg_cfg: dict | None = None):\n",
        "        super(ZeroShotSegmentation, self).__init__()\n",
        "\n",
        "        self.model_name = model_name\n",
        "        self.device = device\n",
        "\n",
        "        self.gem_model = model\n",
        "        self.gem_model.to(device)\n",
        "        self.gem_model.eval()\n",
        "        self.patch_size = patch_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.class_chunk = class_chunk\n",
        "        self.use_ctg = use_ctg\n",
        "        self.ctg = CTGWrapper(patch_size=patch_size, ctg_cfg=ctg_cfg)\n",
        "\n",
        "    def _get_text_embedding(self, classes: list):\n",
        "        prompts = [f'a photo of a {cls}.' for cls in classes]\n",
        "\n",
        "        tokenized_prompts = self.tokenizer(prompts).to(self.device)\n",
        "\n",
        "        text_embedding = self.gem_model.model.encode_text(tokenized_prompts)\n",
        "        text_embedding = F.normalize(text_embedding, dim=-1)\n",
        "        return text_embedding.unsqueeze(0)\n",
        "\n",
        "    def _visual_features(self, image):\n",
        "        with torch.inference_mode(), torch.cuda.amp.autocast(enabled=image.is_cuda):\n",
        "            feat, _ = self.gem_model.model.visual(image)\n",
        "            feat = F.normalize(feat, dim=-1)[:, 1:]\n",
        "        return feat\n",
        "\n",
        "    def inference_chunked(self, image, text_embedding, mask_shape_hw):\n",
        "        B, _, H, W = image.shape\n",
        "\n",
        "        feat = self._visual_features(image)\n",
        "        C = text_embedding.shape[1]\n",
        "\n",
        "        chunks = []\n",
        "        for s in range(0, C, self.class_chunk):\n",
        "            te = text_embedding[:, s:s+self.class_chunk]\n",
        "            lg = 100.0 * torch.matmul(feat, te.transpose(1, 2))\n",
        "            chunks.append(lg)\n",
        "            del te, lg\n",
        "            if image.is_cuda:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        logits_flat = torch.cat(chunks, dim=-1)\n",
        "\n",
        "        h, w = H // self.patch_size, W // self.patch_size\n",
        "        logits = logits_flat.view(B, h, w, C)\n",
        "        logits = logits.permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "        logits = self.ctg.refine(feat_tokens_bnd=feat, H=H, W=W, logits_bchw=logits, mask_shape=mask_shape_hw)\n",
        "        pred = logits.argmax(1)\n",
        "        return pred, logits, feat\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_dataset(self, dataloader, classes, device):\n",
        "        C = len(classes)\n",
        "        text_embedding = self._get_text_embedding(classes)\n",
        "\n",
        "        confmat = np.zeros((C, C), dtype=np.int64)\n",
        "\n",
        "        img_counter = 0\n",
        "\n",
        "        for images, masks in tqdm(dataloader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            pred_gem, logits, feat = self.inference_chunked(\n",
        "                images, text_embedding, masks.shape[-2:]\n",
        "            )\n",
        "\n",
        "            B = images.shape[0]\n",
        "            for b in range(B):\n",
        "                img_path = dataloader.dataset.image_files[img_counter]\n",
        "                img_original = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "                base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "                img_counter += 1\n",
        "\n",
        "                save_predicted_heatmaps(\n",
        "                    img_original,\n",
        "                    logits[b].unsqueeze(0),\n",
        "                    pred_gem[b].unsqueeze(0),\n",
        "                    classes,\n",
        "                    \"./ade_heatmaps_ctg\",\n",
        "                    base_name,\n",
        "                )\n",
        "\n",
        "                gt = masks[b].reshape(-1).cpu()\n",
        "                pr = pred_gem[b].reshape(-1).cpu()\n",
        "\n",
        "                valid = gt >= 0\n",
        "                gt = gt[valid]\n",
        "                pr = pr[valid]\n",
        "\n",
        "                idx = gt * C + pr\n",
        "                cm_flat = torch.bincount(idx, minlength=C*C)\n",
        "                cm = cm_flat.view(C, C).numpy()\n",
        "                confmat += cm\n",
        "\n",
        "        tp = np.diag(confmat).astype(np.float64)\n",
        "        fp = confmat.sum(axis=0) - tp\n",
        "        fn = confmat.sum(axis=1) - tp\n",
        "        denom = tp + fp + fn\n",
        "        iou = np.where(denom > 0, tp / denom, np.nan)\n",
        "        miou = float(np.nanmean(iou) * 100.0)\n",
        "\n",
        "        tag = \"GEM+CTG\" if self.use_ctg else \"GEM\"\n",
        "        print('\\n======================================')\n",
        "        print(f'최종 mIoU ({tag}): {miou:.2f}  (ADE20K 150-class)')\n",
        "        print('======================================')\n",
        "\n",
        "        return miou"
      ],
      "metadata": {
        "id": "6_BBQNS64vSs"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predicted_heatmaps(original_img, logits, pred_mask, classes, save_dir, base_name):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    img = original_img.astype(np.float32) / 255.0\n",
        "    H0, W0, _ = img.shape\n",
        "\n",
        "    pred_classes = torch.unique(pred_mask).cpu().tolist()\n",
        "\n",
        "    for cls_idx in pred_classes:\n",
        "        if cls_idx < 0:\n",
        "            continue\n",
        "\n",
        "        heatmap = logits[0, cls_idx].detach().cpu().numpy()\n",
        "\n",
        "        heatmap = cv2.resize(heatmap, (W0, H0))\n",
        "\n",
        "        if heatmap.max() == heatmap.min():\n",
        "            norm = heatmap\n",
        "        else:\n",
        "            norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
        "\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(\"Original\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(img, alpha=0.5)\n",
        "        plt.imshow(norm, cmap=\"jet\", alpha=0.5)\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"{classes[cls_idx]}\")\n",
        "\n",
        "        filename = f\"{base_name}_{classes[cls_idx]}.png\"\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, filename))\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "WEMNXynH40YD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------\n",
        "# Main\n",
        "# ------------------------------------------------\n",
        "def main(model_name, device, pretrained, patch_size=16, root_path_ade='', batch_size=1, classes_txt='/content/ADE20K_object150.txt',\n",
        "         use_ctg: bool = True,\n",
        "         ctg_cfg: dict | None = None):\n",
        "\n",
        "    dataset = ADE20K(root=root_path_ade, split='validation',\n",
        "                    transform=SegmentationTransforms((448, 448), resize_mask=(batch_size > 1)),\n",
        "                    ignore_index=-1, classes_txt=classes_txt)\n",
        "    classes_list = list(dataset.CLASSES)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=8,\n",
        "        pin_memory=(device.type == \"cuda\")\n",
        "    )\n",
        "\n",
        "    model = gem.create_gem_model(model_name=model_name, pretrained=pretrained)\n",
        "    tokenizer = gem.get_tokenizer(model_name=model_name)\n",
        "\n",
        "    evaluator = ZeroShotSegmentation(model=model,device=device, patch_size=patch_size,\n",
        "                                     model_name=model_name,tokenizer=tokenizer,class_chunk=32,\n",
        "                                     use_ctg=use_ctg, ctg_cfg=ctg_cfg)\n",
        "\n",
        "    miou = evaluator.eval_dataset(\n",
        "        dataloader=test_loader,\n",
        "        classes=classes_list,\n",
        "        device=device\n",
        "    )\n",
        "    return miou\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    patch_size    = 16\n",
        "    model_name    = 'ViT-B-16'\n",
        "    pretrained    = 'openai'\n",
        "    root_path_ade = '/content/ADEChallengeData2016'\n",
        "    classes_txt   = '/content/ADE20K_object150.txt'\n",
        "\n",
        "\n",
        "    ctg_cfg = dict(\n",
        "        pos_ratio=0.10,\n",
        "        neg_ratio=0.10,\n",
        "        alpha=0.3,\n",
        "        tau=9.0,\n",
        "        iters=1,\n",
        "    )\n",
        "\n",
        "    print('########################################')\n",
        "    print(f'model: {model_name} | pretrained: {pretrained}')\n",
        "    print('########################################')\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    final_miou = main(\n",
        "        model_name=model_name,\n",
        "        pretrained=pretrained,\n",
        "        device=device,\n",
        "        patch_size=patch_size,\n",
        "        root_path_ade=root_path_ade,\n",
        "        classes_txt=classes_txt,\n",
        "        batch_size=1,\n",
        "        use_ctg=True,\n",
        "        ctg_cfg=ctg_cfg\n",
        "    )\n",
        "    print(f\"Final mIoU: {final_miou:.2f}\")"
      ],
      "metadata": {
        "id": "66vBbRW-7Rag"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
